# ğŸ® Adaptive Prisonerâ€™s Dilemma â€“ Rule-Based AI Strategy Game

## ğŸ“Œ Overview
This project is a **terminal-based Python implementation** of the **Iterated Prisonerâ€™s Dilemma**, where a human player competes against an **adaptive AI agent**.

Unlike a fixed-rule bot, the AI:
- Observes the playerâ€™s past actions
- Classifies player behavior dynamically
- Adapts its strategy to maximize long-term reward
- Punishes repeated defection but allows forgiveness

The goal is to demonstrate **game theory concepts and AI decision-making** using simple Python logic.

---

## ğŸ§  Core Concepts Used
- Prisonerâ€™s Dilemma (Iterated Version)
- Payoff Matrix
- Opponent Behavior Modeling
- Adaptive Decision Making
- Conditional Cooperation & Delayed Forgiveness

---

## ğŸ•¹ How the Game Works

### 1. Player Choices
In each round, the player chooses:
- `C` â†’ Cooperate  
- `D` â†’ Defect  

The game runs for a user-defined number of rounds.

---

### 2. Payoff Rules
Scores are updated using the standard Prisonerâ€™s Dilemma payoff matrix:

| Player | AI | Player Score | AI Score |
|------|----|-------------|----------|
| C | C | +3 | +3 |
| D | C | +5 | 0 |
| C | D | 0 | +5 |
| D | D | +1 | +1 |

---

## ğŸ¤– AI Decision Logic

### Step 1: Early Exploration
- For the **first 2 rounds**, the AI always cooperates.
- This allows the AI to observe player behavior without judgment.

---

### Step 2: Player Behavior Analysis
After round 2, the AI calculates:
- Cooperation rate
- Defection rate

Based on these rates, the player is classified as:
- **Cooperative** (â‰¥ 70% cooperation)
- **Aggressive** (â‰¥ 70% defection)
- **Opportunistic** (mixed behavior)

This classification is **recomputed every round**, so the AI can forgive and adapt.

---

### Step 3: Strategy Selection
- **Cooperative player** â†’ Tit-for-Tat  
  (AI copies the playerâ€™s previous move)
- **Aggressive player** â†’ Defensive punishment  
  (AI defects only after repeated defection)
- **Opportunistic player** â†’ Cautious Tit-for-Tat  

The AI does **not punish a single defection** and requires **consistent behavior** before changing strategy.

---

### Step 4: Delayed Forgiveness
If the player defected repeatedly, the AI continues to defect **even if the player cooperates once**.
Trust is restored only after consistent cooperation.

This prevents exploitation and models realistic strategic behavior.

---

## ğŸ“Š End of Game Analysis
At the end of the game:
- Final scores are displayed
- Player cooperation rate is calculated
- A conclusion is shown indicating whether trust or aggression led to better outcomes

---

## âœ… Key Features
- Rule-based adaptive AI
- Explainable and transparent decisions
- Prevents short-term exploitation
- Forgiveness is possible but earned
- Simple Python logic with strong AI foundations

---

## ğŸš€ Learning Outcome
This project demonstrates how **AI systems can reason strategically** using game theory principles, making it a strong foundation for:
- Multi-agent systems
- Reinforcement learning
- Decision-making AI

---

## ğŸ“ Note
This is a **rule-based AI agent**.  
The focus is on **logic, reasoning, and adaptability**, which are core AI concepts.
